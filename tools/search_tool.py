# tools/search_tool.py
# This module performs one critical job in the project:
# ‚úîÔ∏è Run a web search
# ‚úîÔ∏è Fetch the top results
# ‚úîÔ∏è Scrape the first paragraph of each webpage to generate richer summaries
# tools/search_tool.py
import requests
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)

def search_web(query: str, max_results: int = 5) -> List[Dict]:
    """
    Search the web using DuckDuckGo API (free, no API key needed)
    
    Args:
        query: Search query
        max_results: Maximum number of results to return
        
    Returns:
        List of search results with title, url, snippet
    """
    try:
        logger.info(f"üîç Searching web for: {query}")
        
        # Using DuckDuckGo HTML scraping (simple approach)
        url = "https://html.duckduckgo.com/html/"
        params = {
            'q': query,
        }
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=10)
        response.raise_for_status()
        
        # Simple parsing (you might want to use BeautifulSoup for production)
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(response.text, 'html.parser')
        
        results = []
        result_divs = soup.find_all('div', class_='result', limit=max_results)
        
        for div in result_divs:
            try:
                # Extract title
                title_elem = div.find('a', class_='result__a')
                title = title_elem.get_text(strip=True) if title_elem else "No title"
                
                # Extract URL
                url_elem = div.find('a', class_='result__url')
                url = url_elem.get('href', '') if url_elem else ""
                if not url.startswith('http'):
                    url = 'https://' + url
                
                # Extract snippet
                snippet_elem = div.find('a', class_='result__snippet')
                snippet = snippet_elem.get_text(strip=True) if snippet_elem else "No description"
                
                results.append({
                    'title': title,
                    'url': url,
                    'snippet': snippet
                })
            except Exception as e:
                logger.warning(f" Error parsing result: {e}")
                continue
        
        logger.info(f" Found {len(results)} search results")
        return results
        
    except requests.RequestException as e:
        logger.error(f" Search request failed: {e}")
        return _fallback_search(query, max_results)
    except Exception as e:
        logger.error(f" Search failed: {e}")
        return _fallback_search(query, max_results)

def _fallback_search(query: str, max_results: int = 5) -> List[Dict]:
    """
    Fallback search results when actual search fails
    """
    logger.warning("‚ö†Ô∏è Using fallback search results")
    
    # Return mock results based on query
    return [
        {
            'title': f'Result 1 about {query}',
            'url': 'https://example.com/1',
            'snippet': f'This is information about {query}...'
        },
        {
            'title': f'Guide to {query}',
            'url': 'https://example.com/2',
            'snippet': f'Comprehensive guide covering {query} topics...'
        },
        {
            'title': f'{query} - Latest Updates',
            'url': 'https://example.com/3',
            'snippet': f'Recent developments and news about {query}...'
        },
        {
            'title': f'Understanding {query}',
            'url': 'https://example.com/4',
            'snippet': f'An in-depth look at {query} and its implications...'
        },
        {
            'title': f'{query} Research Paper',
            'url': 'https://example.com/5',
            'snippet': f'Academic research on {query} and related topics...'
        },
    ][:max_results]